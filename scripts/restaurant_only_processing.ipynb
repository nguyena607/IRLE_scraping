{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f3354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7531d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/alyssanguyen/Desktop/IRLE_scraping/csv_files/raw_prices_carlsjr_non_ca_05162024.csv\"\n",
    "ca_ff = pd.read_csv(file_path)\n",
    "file_path_2 = \"/Users/alyssanguyen/Desktop/IRLE_scraping/csv_files/uszips.csv\"\n",
    "ca_zip_count = pd.read_csv(file_path_2)\n",
    "file_path_3 = \"/Users/alyssanguyen/Desktop/IRLE_scraping/csv_files/processed_prices_ubereats_ca_ff_03222024.csv\"\n",
    "example = pd.read_csv(file_path_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54960f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_zip_count = ca_zip_count[['zip', 'county_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_list(x):\n",
    "    return list(x)\n",
    "def mean_non_zero(x):\n",
    "    return np.mean(x[x != 0]) if np.any(x != 0) else 0\n",
    "\n",
    "def median_non_zero(x):\n",
    "    return np.median(x[x != 0]) if np.any(x != 0) else 0\n",
    "\n",
    "def std_non_zero(x):\n",
    "    return np.std(x[x != 0]) if np.any(x != 0) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all the columns we don't need \n",
    "ca_ff_ = ca_ff.drop(columns=['menu_item_calories'])\n",
    "\n",
    "#Drop all restaurants with no restaurant address \n",
    "#ca_ff_ = ca_ff_.dropna(subset=['restaurant_location'])\n",
    "\n",
    "#Run if doing restaurant-specific processing i.e. Wendy's Hardee's etc \n",
    "\n",
    "ca_ff_ = ca_ff_.rename(columns = {'restaurant_address': \"restaurant_location\"})\n",
    "ca_ff_['restaurant_name'] = 'Carls Jr'\n",
    "ca_ff_['restaurant_rating'] = np.nan\n",
    "ca_ff_['number_of_ratings'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to split prices by \"-\" or \"/\"\n",
    "def split_and_average(price_str):\n",
    "    # Split the price string by \"-\" or \"/\"\n",
    "    prices = re.split(r'[-/]', price_str)\n",
    "    # Convert prices to float and calculate the average\n",
    "    prices = [float(price) for price in prices]\n",
    "    return sum(prices) / len(prices)\n",
    "\n",
    "# Apply the split_and_average function to each row in the menu_item_price column\n",
    "ca_ff_['menu_item_price'] = ca_ff_['menu_item_price'].apply(split_and_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d35c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning up string columns \n",
    "\n",
    "ca_ff_['menu_item'] = ca_ff_['menu_item'].str.lower()\n",
    "ca_ff_['restaurant_location'] = ca_ff_['restaurant_location'].str.lower()\n",
    "ca_ff_['restaurant_name'] = ca_ff_['restaurant_name'].str.replace('_', ' ')\n",
    "\n",
    "#remove special characters\n",
    "ca_ff_['menu_item'] = ca_ff_['menu_item'].apply(lambda x: ''.join(ch for ch in x if ch.isalnum() or ch.isspace()))\n",
    "ca_ff_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997eb7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter to just Wendy's\n",
    "ca_ff_wendy = ca_ff_[ca_ff_['restaurant_name'] == 'Wendy']\n",
    "\n",
    "#First part of grouping \n",
    "\n",
    "agg_funcs = {\n",
    "    'menu_item_price': [mean_non_zero, median_non_zero, std_non_zero],  # calculate the average, median, and standard dev PRICE\n",
    "    'restaurant_rating': 'mean', # calculate the average RATING \n",
    "    'menu_item' : 'count',\n",
    "    'number_of_ratings': 'first'\n",
    "}\n",
    "\n",
    "grouped_wendy = ca_ff_wendy.groupby(['restaurant_name','restaurant_location']).agg(agg_funcs).reset_index()\n",
    "grouped_wendy.columns = [' '.join(col).strip() for col in grouped_wendy.columns.values]\n",
    "\n",
    "# #Second part of grouping \n",
    "wendy_lst = ['daves single', 'french fries', 'jr cheeseburger', 'jr hamburger']\n",
    "\n",
    "# Filter rows where 'menu_item' contains any item in mcd_lst\n",
    "menu_items_wendy = ca_ff_wendy[ca_ff_wendy['menu_item'].isin(wendy_lst)].sort_values('menu_item')\n",
    "menu_items_wendy = menu_items_wendy.drop_duplicates(subset=['restaurant_name', 'restaurant_location', 'menu_item'])\n",
    "\n",
    "grouped_wendy_2 = menu_items_wendy.groupby(['restaurant_name', 'restaurant_location'])['menu_item_price'].agg(price_list).reset_index()\n",
    "\n",
    "grouped_wendy_2[['specialty_item', 'fries', 'cheeseburger', 'hamburger']] = grouped_wendy_2['menu_item_price'].apply(pd.Series)\n",
    "grouped_wendy_2.drop(columns=['menu_item_price'], inplace=True)\n",
    "\n",
    "merged_wendy = pd.merge(grouped_wendy, grouped_wendy_2, on=['restaurant_name', 'restaurant_location'], how='inner')\n",
    "merged_wendy['combo'] = np.nan\n",
    "merged_wendy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter to just Burger King \n",
    "ca_ff_bk = ca_ff_[ca_ff_['restaurant_name'] == 'Burger King']\n",
    "\n",
    "#First part of grouping \n",
    "\n",
    "agg_funcs = {\n",
    "    'menu_item_price': [mean_non_zero, median_non_zero, std_non_zero],  # calculate the average, median, and standard dev PRICE\n",
    "    'restaurant_rating': 'mean', # calculate the average RATING \n",
    "    'menu_item' : 'count',\n",
    "    'number_of_ratings': 'first'\n",
    "}\n",
    "\n",
    "grouped_bk = ca_ff_bk.groupby(['restaurant_name','restaurant_location']).agg(agg_funcs).reset_index()\n",
    "grouped_bk.columns = [' '.join(col).strip() for col in grouped_bk.columns.values]\n",
    "\n",
    "# #Second part of grouping \n",
    "#they don't have a plain hamburger FOR NOW using whopper jr \n",
    "bk_lst = ['cheeseburger', 'french fries', 'whopper', 'whopper jr']\n",
    "\n",
    "# Filter rows where 'menu_item' contains any item in mcd_lst\n",
    "menu_items_bk = ca_ff_bk[ca_ff_bk['menu_item'].isin(bk_lst)].sort_values('menu_item')\n",
    "menu_items_bk = menu_items_bk.drop_duplicates(subset=['restaurant_name', 'restaurant_location', 'menu_item'])\n",
    "\n",
    "grouped_bk_2 = menu_items_bk.groupby(['restaurant_name', 'restaurant_location'])['menu_item_price'].agg(price_list).reset_index()\n",
    "\n",
    "grouped_bk_2[['cheeseburger', 'fries', 'specialty_item', 'hamburger']] = grouped_bk_2['menu_item_price'].apply(pd.Series)\n",
    "grouped_bk_2.drop(columns=['menu_item_price'], inplace=True)\n",
    "\n",
    "merged_bk = pd.merge(grouped_bk, grouped_bk_2, on=['restaurant_name', 'restaurant_location'], how='inner')\n",
    "merged_bk['combo'] = np.nan\n",
    "merged_bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d87e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter to Carl's Jr \n",
    "\n",
    "ca_ff_carls = ca_ff_[ca_ff_['restaurant_name'] == 'Carls Jr']\n",
    "\n",
    "#First part of grouping \n",
    "\n",
    "agg_funcs = {\n",
    "    'menu_item_price': [mean_non_zero, median_non_zero, std_non_zero],  # calculate the average, median, and standard dev PRICE\n",
    "    'restaurant_rating': 'mean', # calculate the average RATING \n",
    "    'menu_item' : 'count',\n",
    "    'number_of_ratings': 'first'\n",
    "}\n",
    "\n",
    "grouped_carls = ca_ff_carls.groupby(['restaurant_name','restaurant_location']).agg(agg_funcs).reset_index()\n",
    "grouped_carls.columns = [' '.join(col).strip() for col in grouped_carls.columns.values]\n",
    "\n",
    "\n",
    "#Second part of grouping \n",
    "carls_lst = ['california classic double cheeseburger', 'single big carl']\n",
    "\n",
    "# Filter rows where 'menu_item' contains any item in mcd_lst\n",
    "menu_items_carls = ca_ff_carls[ca_ff_carls['menu_item'].isin(carls_lst)].sort_values('menu_item')\n",
    "menu_items_carls = menu_items_carls.drop_duplicates(subset=['restaurant_name', 'restaurant_location', 'menu_item'])\n",
    "\n",
    "grouped_carls_2 = menu_items_carls.groupby(['restaurant_name', 'restaurant_location'])['menu_item_price'].agg(price_list).reset_index()\n",
    "\n",
    "grouped_carls_2[['cheeseburger', 'specialty_item']] = grouped_carls_2['menu_item_price'].apply(pd.Series)\n",
    "grouped_carls_2.drop(columns=['menu_item_price'], inplace=True)\n",
    "\n",
    "#Merging the grouped dfs together \n",
    "merged_carls = pd.merge(grouped_carls, grouped_carls_2, on=['restaurant_name', 'restaurant_location'], how='inner')\n",
    "merged_carls['fries'] = np.nan\n",
    "merged_carls['combo'] = np.nan\n",
    "merged_carls['hamburger'] = np.nan\n",
    "\n",
    "merged_carls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694614eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_items_carls['menu_item'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\",\\s*([a-zA-Z]{2})\\s*,?\\s*(\\d{5}(?:-\\d{4})?)\"\n",
    "\n",
    "def extract_state_zip(address):\n",
    "    match = re.search(pattern, address)\n",
    "    if match:\n",
    "        state, zip_code = match.groups()\n",
    "        return state, zip_code\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Apply the function to extract state and zip code\n",
    "merged_carls[['state', 'zip']] = merged_carls['restaurant_location'].apply(lambda x: pd.Series(extract_state_zip(x)))\n",
    "merged_carls['zip'] = merged_carls['zip'].str.split('-').str[0].astype(int)\n",
    "\n",
    "#Get county \n",
    "merged_carls = merged_bk.merge(ca_zip_count, on = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_date = datetime.strptime('05162024', '%m%d%Y')\n",
    "# Assign the datetime object to the entire 'date' column\n",
    "merged_carls['date'] = specific_date\n",
    "merged_carls['uber_eats'] = 0\n",
    "merged_carls['post_policy'] = 1\n",
    "merged_carls['fast_food'] = 1 \n",
    "merged_carls['local'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137619e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_carls.to_csv(\"processed_prices_carlsjr_nonca_05162024.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
